{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Running a simulation with SHyFT\n",
    "=========\n",
    "\n",
    "### This notebook is guiding through the simulation process of a catchment. The following steps are described:\n",
    "1. **Loading required python modules and setting path to SHyFT installation**\n",
    "2. **Configuration of a SHyFT simulation**\n",
    "3. **Running a SHyFT simulation**\n",
    "4. **Post-processing:** Fetching simulation results from the simulator-object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first you should import the third-party python modules which you'll use later on\n",
    "# the first line enables that figures are shown inline, directly in the notebook\n",
    "%pylab inline\n",
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading required python modules and setting path to SHyFT installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the path for your shyft build\n",
    "# this should point to the directory that is created\n",
    "# when you clone shyft, assuming you have built shyft\n",
    "# there and not installed it to your system python\n",
    "shyft_path = os.path.abspath(\"../../../shyft\")\n",
    "sys.path.insert(0, shyft_path)\n",
    "\n",
    "# you could achieve the same by setting a PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# once the shyft_path is set correctly, you should be able to import shyft modules\n",
    "import shyft\n",
    "from shyft import shyftdata_dir\n",
    "\n",
    "# if you have problems here, it may be related to having your LD_LIBRARY_PATH\n",
    "# pointing to the appropriate libboost_python libraries (.so files)\n",
    "from shyft.repository.default_state_repository import DefaultStateRepository\n",
    "from shyft.orchestration.configuration import yaml_configs\n",
    "from shyft.orchestration.simulators.config_simulator import ConfigSimulator\n",
    "from shyft import api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration of a SHyFT simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now you can access the api of shyft with tab completion and help, try this:\n",
    "\n",
    "#help(api.GeoPoint) # remove the hashtag and run the cell to print the documentation of the api.GeoPoint class\n",
    "#api. # remove the hashtag, set the pointer behind the dot and use \n",
    "      # tab completion to see the available attributes of the shyft api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up configuration using *.yaml configuration files\n",
    "# here is the *.yaml file that configures the simulation:\n",
    "config_file_path = os.path.abspath(\"./sagelva-config/sagelva_hbv/sagelva_simulation.yaml\")\n",
    "\n",
    "# and here we pass it to the configurator, together with the name of the region \n",
    "# stated in the simulation.yaml file (here: \"neanidelva\") which we would like to run\n",
    "cfg = yaml_configs.YAMLSimConfig(config_file_path, \"sagelva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Once we have all the configuration in place (read in from the .yaml files)\n",
    "# we can start to do the simulation. Here we use the ConfigSimulator class \n",
    "# to initialize a simulator-object. Shyft has several ways to achieve this\n",
    "# but the .yaml configs are the most straight forward\n",
    "\n",
    "simulator = ConfigSimulator(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now the simulator is ready to run! You can explore this object with tab\n",
    "# completion. As an example, you can see here how to get the number of cells\n",
    "# in the region that was set up. This is used later for extracting the data.\n",
    "\n",
    "n_cells = simulator.region_model.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need to instantiate a state_repos repository from the DefaultStateRepository class\n",
    "# this will be used to provide initial values for the state variables of the simulation\n",
    "state_repos = DefaultStateRepository(simulator.region_model.__class__, n_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running a SHyFT simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To run a simulation, we need a time_axis (length of the simulation), and\n",
    "# an initial state. We get the time_axis from the cfg object (which takes it\n",
    "# from the .yaml files) and the state we constructed above.\n",
    "\n",
    "simulator.run(cfg.time_axis, state_repos.get_state(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Post processing\n",
    "####Examples for fetching data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####a) Get the discharge for each (sub-) catchment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we are going to extact data from the simulator object.\n",
    "# We start by creating a list to hold discharge for each of the subcatchments.\n",
    "# Then we'll get the data from the simulator object\n",
    "\n",
    "# mapping of internal catch ID to catchment\n",
    "catchment_id_map = simulator.region_model.catchment_id_map \n",
    "\n",
    "# api.TsVector() is a list of api.Timeseries type. \n",
    "discharge_ts = api.TsVector() #  except from the type, it just works as a list()\n",
    "# loop over each catchment, and extract the time-series (we keep them as such for now)\n",
    "for cid in catchment_id_map: # fill in discharge time series for all subcatchments\n",
    "    discharge_ts.append(simulator.region_model.statistics.discharge([int(cid)]))\n",
    "    # discharge is a TS object,keeping a .time_axis and .values\n",
    "    # we can always do .values.to_numpy() to get the numpy array of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can make a quick plot of the data of each sub-catchment\n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "\n",
    "# plot each catchment discharge in the catchment_id_map\n",
    "for i,ts in enumerate(discharge_ts):\n",
    "    # a ts.time_axis can be enumerated to it's UtcPeriod, that have a .start and .end of type utctimestamp\n",
    "    # since matplotlib do have built in support for datetime-axis, we convert it to datetime\n",
    "    ts_timestamps = [datetime.datetime.utcfromtimestamp(p.start) for p in ts.time_axis]\n",
    "    ts_values = ts.values # iterable and convertible, .to_numpy() makes an np array\n",
    "    ax.plot(ts_timestamps,ts_values, label = \"{}\".format(catchment_id_map[i]))\n",
    "fig.autofmt_xdate()\n",
    "ax.legend(title=\"Catch. ID\")\n",
    "ax.set_ylabel(\"discharge [m3 s-1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# now we can also plot the statistical distribution of the discharges over the sub-catchments\n",
    "#\n",
    "percentiles= api.IntVector([10,25,50,-1,75,90])  # the percentiles we want, note -1 = arithmetic average\n",
    "\n",
    "# create a Daily(for the fun of it!) time-axis for the percentile calculations(our simulation could be hourly)\n",
    "ta_statistics = api.Timeaxis2(simulator.region_model.time_axis.time(0),api.Calendar.DAY,365)\n",
    "\n",
    "# then simply get out a new set of time-series, corresponding to the percentiles we specified\n",
    "discharge_percentiles = api.percentiles(discharge_ts,ta_statistics,percentiles)\n",
    "\n",
    "#utilize that we know that all the percentile time-series share a common time-axis\n",
    "common_timestamps = [datetime.datetime.utcfromtimestamp(p.start) for p in ta_statistics] \n",
    "\n",
    "# Then we can make another plot of the percentile data for the sub-catchments\n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "\n",
    "# plot each discharge percentile in the discharge_percentiles\n",
    "for i,ts_percentile in enumerate(discharge_percentiles):\n",
    "    clr='k'\n",
    "    if percentiles[i] >= 0.0: \n",
    "        clr= str(float(percentiles[i]/100.0))\n",
    "    ax.plot(common_timestamps, ts_percentile.values, label = \"{}\".format(percentiles[i]),color=clr)\n",
    "\n",
    "# also plot catchment discharge along with the statistics\n",
    "# notice that we use .average(ta_statistics) to properly align true-average values to time-axis\n",
    "ax.plot(common_timestamps,discharge_ts[0].average(ta_statistics).values,label = \"CID {}\".format(catchment_id_map[0]),linewidth=2.0,alpha=0.7,color='b')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "ax.legend(title=\"Percentiles\")\n",
    "ax.set_ylabel(\"discharge [m3 s-1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a simple percentile plot, from orchestration looks nicer\n",
    "from shyft.orchestration import plotting as splt\n",
    "oslo=api.Calendar('Europe/Oslo')\n",
    "fig,ax=plt.subplots(figsize=(16,8))\n",
    "splt.set_calendar_formatter(oslo)\n",
    "h,ph=splt.plot_np_percentiles(common_timestamps,[ p.values.to_numpy() for p in discharge_percentiles],base_color=(0.03,0.01,0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If we're interested to look at values of individual cells, rather\n",
    "# than at the catchment level, we can do that also. Shyft does not have\n",
    "# an underlying 'raster' model, so you need to fetch all cells directlry\n",
    "# from the simulator object\n",
    "cells = simulator.region_model.get_cells()\n",
    "\n",
    "# Once we have the cells, we can get their coordinate information\n",
    "# and fetch the x- and y-location of the cells\n",
    "x = [cell.geo.mid_point().x for cell in cells]\n",
    "y = [cell.geo.mid_point().y for cell in cells]\n",
    "\n",
    "\n",
    "# If you want to know the membership to each catchment\n",
    "# of the cells, you can get a list of catchment ids for each cell\n",
    "cid_z_map = dict([ (catchment_id_map[i],i) for i in range(len(catchment_id_map))])\n",
    "catch_ids = np.array([cid_z_map[cell.geo.catchment_id()] for cell in cells])\n",
    "\n",
    "# and make a quick catchment map...\n",
    "# using a scatter plot of the cells\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "cm = plt.cm.get_cmap('rainbow')\n",
    "plot = ax.scatter(x, y, c=catch_ids, marker='.', s=40, lw=0, cmap=cm)\n",
    "plt.colorbar(plot).set_label('zero-based mapping(proper map tbd)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####b) Get the Snow Cover Fraction (SCF) of all cells for a certain point in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Here we'll do some more work to look at the timeseries data in each of the cells\n",
    "# This example is collecting the response variable (here the SCF)\n",
    "# for each of the cells for a certain point of time.\n",
    "# set a date: year, month, day, (hour of day if hourly time step)\n",
    "oslo = api.Calendar('Europe/Oslo') # specifying input calendar in olson tz-id\n",
    "time_x = oslo.time(1991,1,15)  # the oslo calendar(incl dst) converts calendar coordinates Y,M,D.. to its utc-time\n",
    "\n",
    "try:\n",
    "    idx = simulator.region_model.time_axis.index_of(time_x) # index of time x on time-axis\n",
    "except:\n",
    "    print(\"Date out of range, setting index to 0\")\n",
    "    idx = 0\n",
    "\n",
    "# fetching SCF (the response variable is named \"snow_sca\")\n",
    "# You can use tab-completion to explore the `rc`, short for \"response collector\"\n",
    "# object of the cell, to see further response variables available.\n",
    "scf = simulator.region_model.hbv_snow_response.outflow([],idx) # specifying empty list [] indicates all catchments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And finally we can make a simple scatter plot for quick visualization\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "cm = plt.cm.get_cmap('summer')\n",
    "plot = ax.scatter(x, y, c=scf, vmin=0, vmax=1, marker='s', s=40, lw=0, cmap=cm)\n",
    "plt.colorbar(plot)\n",
    "plt.title('Snow Covered area of {0} on {1}'.format(cfg.region_model_id, oslo.to_string(time_x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And let's compute histogram of the snow covered area as well\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.hist(scf, bins=20, range=(0,1), color='y', alpha=0.5)\n",
    "ax.set_xlabel(\"SCF of grid cell\")\n",
    "ax.set_ylabel(\"frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
